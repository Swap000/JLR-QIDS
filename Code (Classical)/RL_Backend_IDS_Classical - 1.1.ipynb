{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.29.1)\n",
      "Requirement already satisfied: stable-baselines3 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: torch in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.0-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.3.0-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3) (3.8.4)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->stable-baselines3) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->stable-baselines3) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->stable-baselines3) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->stable-baselines3) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->stable-baselines3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->stable-baselines3) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\deshm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Downloading torchvision-0.18.0-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.5/1.2 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 0.9/1.2 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.3.0-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 15.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 16.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.4 MB 17.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 16.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 16.7 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.3.0 torchvision-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium stable-baselines3 numpy tensorflow torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, BaseCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom Gymnasium environment for Network Intrusion Detection\n",
    "class NetworkIntrusionEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gymnasium interface for IDS\"\"\"\n",
    "    metadata = {'render_modes': ['console']}\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NetworkIntrusionEnv, self).__init__()\n",
    "        # Defining action space (0: benign, 1: malicious)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        # Defining observation space as an example with 5 features\n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(5,), dtype=np.float32)\n",
    "        \n",
    "        # Generating an initial state\n",
    "        self.state = np.random.rand(5)\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Adding support for the seed parameter\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.state = np.random.rand(5)\n",
    "        self.steps_beyond_done = None\n",
    "        return np.array(self.state, dtype=np.float32), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Implement your step logic here\n",
    "        self.state = np.random.rand(5)\n",
    "        reward = self.is_malicious(self.state)\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        return np.array(self.state, dtype=np.float32), reward, terminated, truncated, info\n",
    "\n",
    "    def render(self, mode='console'):\n",
    "        if mode == 'console':\n",
    "            print(f'Current state: {self.state}')\n",
    "\n",
    "    def is_malicious(self, state):\n",
    "        # Defining malicious condition, example combining several features\n",
    "        # Logic based on abnormal values typically seen in attacks\n",
    "        # Example: High packet rate and low error rate might indicate flooding attack\n",
    "        high_packet_rate = state[1] > 0.7\n",
    "        low_error_rate = state[3] < 0.05\n",
    "        large_payload = state[4] > 0.8\n",
    "        return int(high_packet_rate and low_error_rate or large_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to print training progress\n",
    "class ProgressCallback(BaseCallback):\n",
    "    def __init__(self, total_timesteps, verbose=0):\n",
    "        super(ProgressCallback, self).__init__(verbose)\n",
    "        self.total_timesteps = total_timesteps\n",
    "        self.start_time = None\n",
    "        self.epoch_rewards = []\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        self.start_time = time.time()\n",
    "        self.epoch_rewards = []\n",
    "        print(\"Training started.\")\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.model.n_steps == 0:\n",
    "            elapsed_time = time.time() - self.start_time\n",
    "            remaining_time = (self.total_timesteps - self.num_timesteps) / self.num_timesteps * elapsed_time\n",
    "            mean_reward = np.mean(self.locals['rewards'])\n",
    "            self.epoch_rewards.append(mean_reward)\n",
    "            epoch = len(self.epoch_rewards)\n",
    "            print(f\"Epoch: {epoch}, Step: {self.num_timesteps}, Elapsed Time: {elapsed_time:.2f}s, Remaining Time: {remaining_time:.2f}s, Mean Reward: {mean_reward:.2f}\")\n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self) -> None:\n",
    "        total_time = time.time() - self.start_time\n",
    "        print(f\"Training completed in {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the environment and checking it\n",
    "env = NetworkIntrusionEnv()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping the environment to make it compatible with stable-baselines3\n",
    "vec_env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning (We would extend this with a grid search or similar approach)\n",
    "hyperparams = {\n",
    "    'n_steps': 2048,\n",
    "    'batch_size': 64,\n",
    "    'n_epochs': 10,\n",
    "    'learning_rate': 0.0003\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Setting up PPO agent with the appropriate device\n",
    "model = PPO(\"MlpPolicy\", vec_env, verbose=1, tensorboard_log=\"./ids_tensorboard/\", device=device, **hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up evaluation callback and custom progress callback\n",
    "eval_callback = EvalCallback(vec_env, best_model_save_path='./ids_rl_model/', log_path='./ids_logs/', eval_freq=500, deterministic=True, render=False)\n",
    "progress_callback = ProgressCallback(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ids_tensorboard/PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training the agent\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_callback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:201\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n\u001b[0;32m    200\u001b[0m callback\u001b[38;5;241m.\u001b[39mupdate_locals(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[1;32m--> 201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_info_buffer(infos, dones)\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:114\u001b[0m, in \u001b[0;36mBaseCallback.on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:460\u001b[0m, in \u001b[0;36mEvalCallback._on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;66;03m# Reset success rate buffer\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_success_buffer \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 460\u001b[0m episode_rewards, episode_lengths \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_policy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_episode_rewards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_success_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(episode_rewards, \u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:88\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[1;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[0;32m     86\u001b[0m episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((env\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (episode_counts \u001b[38;5;241m<\u001b[39m episode_count_targets)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m---> 88\u001b[0m     actions, states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisode_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     new_observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n\u001b[0;32m     95\u001b[0m     current_rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rewards\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    538\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[0;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:368\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_to_tensor(observation)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[0;32m    370\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:717\u001b[0m, in \u001b[0;36mActorCriticPolicy._predict\u001b[1;34m(self, observation, deterministic)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: PyTorchObs, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    710\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;124;03m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;124;03m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:752\u001b[0m, in \u001b[0;36mActorCriticPolicy.get_distribution\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    750\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mextract_features(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi_features_extractor)\n\u001b[0;32m    751\u001b[0m latent_pi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_actor(features)\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:697\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[1;34m(self, latent_pi)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(mean_actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_std)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, MultiCategoricalDistribution):\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the flattened logits\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(action_logits\u001b[38;5;241m=\u001b[39mmean_actions)\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:288\u001b[0m, in \u001b[0;36mCategoricalDistribution.proba_distribution\u001b[1;34m(self, action_logits)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproba_distribution\u001b[39m(\u001b[38;5;28mself\u001b[39m: SelfCategoricalDistribution, action_logits: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfCategoricalDistribution:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\deshm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributions\\categorical.py:64\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`logits` parameter must be at least one-dimensional.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits \u001b[38;5;241m=\u001b[39m logits \u001b[38;5;241m-\u001b[39m \u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogsumexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobs \u001b[38;5;28;01mif\u001b[39;00m probs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the agent\n",
    "model.learn(total_timesteps=10000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3645560766.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f'Mean reward: {mean_reward} +/- {std_reward}'\u001b[0m\n\u001b[1;37m                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the trained agent\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Optional Model Saving\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIDS_Network_PPO_Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Optional Model Saving\n",
    "model.save(\"IDS_Network_PPO_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
